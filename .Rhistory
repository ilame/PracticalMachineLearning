mkdir HelloWorld.md
touch HelloWorld.md
## This is a markdown file
## This is a markdown file
## This is a markdown file
## This is a markdown file
install.packages("KernSmooth")
getwd()
dir
cd
source("cachematrix.R")
LS
ls
cd
dir
getwd()
getwd()
source("cachematrix.R")
load("C:/Users/maroc/Desktop/Coursera/ProgrammingAssignment2/cachematrix.R")
source("cachematrix.R")
load("C:/Users/maroc/Desktop/Coursera/ProgrammingAssignment2/cachematrix.R")
load("C:/Users/maroc/Desktop/Coursera/ProgrammingAssignment2/cachematrix.R")
source("cachematrix.R")
n=length(typos.draft2)
typos.draft1 = c(2,3,0,3,1,0,0,1)
n=length(typos.draft2)
n=length(typos.draft1)
pages = 1:n
pages
pages[typos.draft1 == 3]
seq()
?seq
a:b
seq(a,b,1)
seq(1,n,1)
(1:length(typos.draft2))[typos.draft2 == max(typos.draft2)]
(1:length(typos.draft1))[typos.draft1 == max(typos.draft1)]
x = c(45,43,46,48,51,46,50,47,46,45)
x = c(x,48,49,51,50,49,41,40,38,35,40)
X
x
day=5
mean(x[day:(day+4)]
mean(x[day:(day+4)])
mean(x[day:(day+4)])
cummax(x)
cummin(x)
whale = c(74, 122, 235, 111, 292, 111, 211, 133, 156, 79)
mean(whale)
var(whale)
std(whale)
sqrt(var(whale))
sqrt(sum((whale - mean(whale))^2/(length(whale)-1)))
std=function(x)sqrt(var(x))
std(whale)
sd(whale)
miles = c(65311, 65624, 65908, 66219, 66499, 66821, 67145, 67447)
x = diff(miles)
x
max(x)
mean(x)
min(x)
com = c(17, 16, 20, 24, 22, 15, 21, 15, 17, 22)
com[4]=18
COM
com
com[>=20]
com[>= 20]
sum( com[>= 20])
sum( com >= 20)
sum( com <17)
sum( com <17)/length(com)
x = c(1,3,5,7,9)
y = c(2,3,5,7,11,13)
x+1
y
y*2
length(x)
length(y)
x+y
sum(x>5)
sum(x[x>5])
sum(x>5 | x<3)
sum(x>5 & x<3)
y[-3]
y[x]
y[y>=7]
x = c(1, 8, 2, 6, 3, 8, 5, 5, 5, 5)
mean(x)
sum(x)/10
log(x[1])
log(x[2])
log(x[3])
log(x[4])
log(x[5])
log(x[6])
log(x[7])
log(x[8])
log(x[9])
log(x[10])
for i in 1:10 {
for i in 1:10 { y[i]<- (x[i] - 4.4)/2.875 }
i=as.numeric()
for i in 1:10 { y[i]<- (x[i] - 4.4)/2.875 }
range(x)
for i in 1:10 do { y[i]<- (x[i] - 4.4)/2.875 }
id=1:10
for i in id do { y[i]<- (x[i] - 4.4)/2.875 }
for (i in id) do { y[i]<- (x[i] - 4.4)/2.875 }
max(x) - min(x)
beer=scan()
barplot(beer)
barplot(table(beer))
barplot(table(beer))/length(beer))
barplot(table(beer)/length(beer))
beer.counts = table(beer)
pie(beer.counts)
names(beer.counts) = c("domestic\n can","Domestic\n bottle",
"Microbrew","Import")
pie(beer.counts)
pie(beer.counts,col=c("purple","green2","cyan","white"))
sals = scan()
mean(sals)
var(sals)
sd(sals)
median(sals)
fivenum(sals)
summary(sals)
mean(sals,trim=1/10)
mean(sals,trim=2/10)
mean(sals,trim=1/2)
?stem
scores=scan()
stem(scores)
stem(scores,scale=2)
q()
sals = c(12, .4, 5, 2, 50, 8, 3, 1, 4, .25)
cats = cut(sals,breaks=c(0,1,5,max(sals)))
cats
table(cats)
levels(cats) = c("poor","rich","rolling in it")
table(cats)
x=scan()
hist(x)
hist(x,probability=TRUE)
hist(x,probability=TRUE)
hist(x)
hist(x,probability=TRUE)
hist(x)
rug(jitter(x))
hist(x,probability=TRUE)
rug(jitter(x))
q()
q()
1.1+c(-1,1)*qt(.975)*30
1.1+c(-1,1)*qt(.975,8)*30
1100+c(-1,1)*qt(.975,8)*30
s<-2*sqrt(9)/qt(.975,8)
s
3-5+c(-1,1)*qt(.975,18)*sqrt(0.6)/sqrt(20)
3-5+c(-1,1)*qt(.975,18)*sqrt(0.68)/sqrt(20)
t.test(3,5,paired=FALSE,var.equal=TRUE)$conf
t.test(3,5)$conf.int
t.test(5,3)$conf.int
3-5+c(-1,1)*qt(.975,18)*sqrt(0.68)/sqrt(.2)
3-5+c(-1,1)*qt(.975,18)*sqrt(0.64)/sqrt(.2)
3-5+c(-1,1)*qt(.975,18)*sqrt(0.64)/sqrt(20)
3-5+c(-1,1)*qt(.975,18)*sqrt(0.6)/sqrt(20)
3-5+c(-1,1)*qt(.95,18)*sqrt(0.6)/sqrt(20)
3-5+c(-1,1)*qt(.95,18)*sqrt(0.68)/sqrt(20)
3-5+c(-1,1)*qt(.95,20)*sqrt(0.68)/sqrt(20)
3-5+c(-1,1)*qt(.975,20)*sqrt(0.68)/sqrt(20)
(3-5)+c(-1,1)*qt(.975,20)*sqrt(0.68)/sqrt(20)
(3-5)+c(-1,1)*qt(.975,18)*sqrt(0.68)/sqrt(20)
(3-5)+c(-1,1)*qt(.975,18)*sqrt(0.68)/sqrt(10)
(3-5)+c(-1,1)*qt(.975,9)*sqrt(0.68)/sqrt(10)
(3-5)+c(-1,1)*qt(.975,18)*sqrt(18*0.6)/sqrt(20)
(3-5)+c(-1,1)*qt(.975,18)*sqrt(18*0.6/18)/sqrt(20)
(3-5)+c(-1,1)*qt(.95,18)*sqrt(18*0.6/18)/sqrt(20)
(3-5)+c(-1,1)*qt(.95,18)*sqrt((9*0.6+9*0.68)/18)*sqrt(0.2)
nx<-10
ny<-10
xbar<-5
ybar-<3
varx<-.68
vary<-.6
spp<-((nx-1)*varx+(ny-1)*vary)/(nx+ny-2)
sp<-sqrt(spp)
ts<-qt(0.975,nx+ny-2)
(ybar-xbar)+c(-1,1)*ts*sp*sqrt((1/nx)+(1/ny))
ybar<-3
(ybar-xbar)+c(-1,1)*ts*sp*sqrt((1/nx)+(1/ny))
(3-5)+c(-1,1)*qt(0.975,18)*sqrt(9*1.28/18)*sqrt((1/10)+(1/10))
3-5+c(-1,1)*qt(.975,18)*sqrt(0.64)*sqrt(.2)
(-3-1)+c(-1,1)*qt(.9,16)*sqrt((1.5^2+1.8^2)/2)*sqrt(2/9)
(-3-1)+c(-1,1)*qt(.975,16)*sqrt((1.5^2+1.8^2)/2)*sqrt(2/9)
(-3-1)+c(-1,1)*qt(.95,16)*sqrt((1.5^2+1.8^2)/2)*sqrt(2/9)
1100+c(-1,1)*qt(.975,8)*30*sqrt(1/9)
library(datasets)
data(ToothGrowth)
t.test(len ~ supp, data = ToothGrowth)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mean(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x-1)
data(mtcars)
coef(lm(mpg~weight)
)
coef(lm(mtcars$mpg~mtcars$weight))
head(mtcars)
coef(lm(mtcars$mpg~mtcars$wt))
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
y<-mean(x)
s<-sd(x)
s
n<-(x-y)/s
n
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
coef(lm(y~x))
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
m<-mean(x)
s<-sum((x-m)^2)
cov<-s/9
sd<-sd(x)
cor<-cov/sd^2
cor
m
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
weighted.mean(x, w)
z<-x*w
z
mean(z)
mean(x*w)
q()
library(swirl)
swirl()
cor(gpa_nor,gch_nor)
l_nor<-lm(gch_nor,gpa_nor)
l_nor<-lm(gch_nor ~ gpa_nor)
lm(galton$child ~ galton$parent)
fit<-lm(galton$child ~ galton$parent)
fit<-lm(galton$child ~ galton$parent,galton)
fit<-lm(child ~ parent,galton)
sum(fit$residuals)/928
sum(fit$residuals)/926
sum(fit$residuals^2)/926
sqrt(sum(fit$residuals^2)/926)
sqrt(sum(fit$residuals^2)/n-2)
sqrt(sum(fit$residuals^2)/(n-2)
)
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu<-mean(galton$child)
sTot<-sum((galton$child - mu)^2)
sRes<-deviance(lm(galton$child~galton$height))
sRes<-deviance(lm(galton$child~galton$height,galton))
sRes<-deviance(lm(galton$child~galton$parent,galton))
sRes<-deviance(lm(galton$child~galton$parent))
sRes<-deviance(fit)
1-(sRes/sTot)
1-sRes/sTot
summary(fit)$r.squared
cor(galton$child,galton$parent)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent -1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
head(trees)
fit <- lm(Volume ~ Girth + Height + Constant -1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant -1,
| trees2)
fit2 <- lm(Volume ~ Height + Constant -1,
| trees2)
fit2 <- lm(Volume ~ Height + Constant -1, trees)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
dataset(mtcars)
library(datasets)
dataset(mtcars)
head(mtcars)
fit<-lm(mpg~cyl+wt,mtcars)
str(mtcars)
cyl<-as.factor(mtcars$cyl)
str(mtcars)
mtcars$cyl<-as.factor(mtcars$cyl)
str(mtcars)
fit<-lm(mpg~cyl+wt,mtcars)
summary(fit)
fit2<-lm(mpg~cyl,mtcars)
summary(fit2)
fit3<-lm(mpg~cyl*wt,mtcars)
summary(fit3)
anova(fit,fit3)
anova(fit,fit3,test="chi")
anova(fit,fit3,test="Chi")
?anova
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit<-lm(y~x)
lm.influence(fit)
hatvalues(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
dfbetas(fit)
?shuttle
library(swirl)
swirl()
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(caret)
install.packages("caret")
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
data(concrete)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
library(AppliedPredictiveModeling)
library(caret)
data(concrete)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(concrete)
intrain
inTrain
mixtures
head(mixtures)
head(concrete)
adData = data.frame(diagnosis,predictors)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(training)
IL_str <- grep("^IL", colnames(training), value = TRUE)
IL_str
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.9)
preProc$rotation
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
install.packages("e1071")
library(e1071)
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
modelFit <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca",
data = training, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
library(caret)
ptrain <- read.csv("pml-training.csv")
setwd("C:/Users/maroc/Desktop/Coursera/ML")
ptrain <- read.csv("pml-training.csv")
ptest <- read.csv("pml-testing.csv")
ptest <- read.csv("pml-testing.csv")
set.seed(10)
inTrain <- createDataPartition(y=ptrain$classe, p=0.7, list=F)
ptrain1 <- ptrain[inTrain, ]
ptrain2 <- ptrain[-inTrain, ]
nzv <- nearZeroVar(ptrain1)
ptrain1 <- ptrain1[, -nzv]
ptrain2 <- ptrain2[, -nzv]
mostlyNA <- sapply(ptrain1, function(x) mean(is.na(x))) > 0.95
ptrain1 <- ptrain1[, mostlyNA==F]
ptrain2 <- ptrain2[, mostlyNA==F]
ptrain1 <- ptrain1[, -(1:5)]
ptrain2 <- ptrain2[, -(1:5)]
fitControl <- trainControl(method="cv", number=3, verboseIter=F)
fit <- train(classe ~ ., data=ptrain1, method="rf", trControl=fitControl)
fit$finalModel
preds <- predict(fit, newdata=ptrain2)
confusionMatrix(ptrain2$classe, preds)
nzv <- nearZeroVar(ptrain)
ptrain <- ptrain[, -nzv]
ptest <- ptest[, -nzv]
mostlyNA <- sapply(ptrain, function(x) mean(is.na(x))) > 0.95
ptrain <- ptrain[, mostlyNA==F]
ptest <- ptest[, mostlyNA==F]
ptrain <- ptrain[, -(1:5)]
ptest <- ptest[, -(1:5)]
fitControl <- trainControl(method="cv", number=3, verboseIter=F)
fit <- train(classe ~ ., data=ptrain, method="rf", trControl=fitControl)
preds <- predict(fit, newdata=ptest)
preds <- as.character(preds)
pml_write_files <- function(x) {
n <- length(x)
for(i in 1:n) {
filename <- paste0("problem_id_", i, ".txt")
write.table(x[i], file=filename, quote=F, row.names=F, col.names=F)
}
}
pml_write_files(preds)
